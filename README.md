# Housing Price Prediction

## Project Overview
This project aims to predict house prices using machine learning models. The dataset consists of numerical and categorical features that influence housing prices. The workflow includes data preprocessing, feature engineering, model training, and evaluation to determine the best-performing model.

## Steps Followed

### 1Ô∏è‚É£ Data Preparation
- Imported essential libraries (`numpy`, `pandas`, `matplotlib`, `seaborn`, `sklearn`).
- Loaded the dataset and examined its structure.
- Identified feature types (numerical, categorical) and handled missing values.

### 2Ô∏è‚É£ Exploratory Data Analysis (EDA)
- Plotted scatterplots to identify trends and outliers.
- Generated a correlation heatmap to find the most important features.
- Analyzed the `SalePrice` distribution to check for skewness.

### 3Ô∏è‚É£ Feature Engineering
Created new features to enhance model performance:

- `HouseAge = YrSold - YearBuilt` (Age of house since built)
- `HouseRemodelAge = YrSold - YearRemodAdd` (Years since last remodel)
- `TotalSF = 1stFlrSF + 2ndFlrSF + BsmtFinSF1 + BsmtFinSF2` (Total square footage)
- `TotalArea = GrLivArea + TotalBsmtSF` (Total living + basement area)
- `TotalBaths = BsmtFullBath + FullBath + 0.5 * (BsmtHalfBath + HalfBath)` (Total bathrooms, where half baths count as 0.5)
- `TotalPorchSF = OpenPorchSF + 3SsnPorch + EnclosedPorch + ScreenPorch + WoodDeckSF` (Total porch and deck space)
- Dropped irrelevant or highly correlated features.

### 4Ô∏è‚É£ Data Preprocessing
#### Categorical Features
- Ordinal features ‚Üí Encoded using `OrdinalEncoder`.
- Nominal features ‚Üí Applied `OneHotEncoding`.

#### Numerical Features
- Handled missing values.
- Standardized using `StandardScaler`.
- Combined all transformations using `ColumnTransformer`.

### 5Ô∏è‚É£ Target Variable Transformation
- Applied log transformation: `np.log1p(SalePrice)` to normalize the target variable.

### 6Ô∏è‚É£ Model Training & Evaluation
Split data into **80% training / 20% testing** and trained multiple models:
‚úÖ Linear Regression  
‚úÖ Random Forest Regressor (with `GridSearchCV` for hyperparameter tuning)  
‚úÖ XGBoost  
‚úÖ Ridge Regression  
‚úÖ Gradient Boosting Regressor  
‚úÖ LGBM Regressor (with Cross Validation)  
‚úÖ CatBoost Regressor  

**Evaluation Metric:** Root Mean Squared Error (RMSE)

### 7Ô∏è‚É£ Stacking & Voting Regressor for Final Prediction
- Implemented **Voting Regressor** to combine multiple models based on their performance.
- Implemented **Stacking Regressor**, leveraging multiple algorithms to enhance predictive power.
- Selected **Voting Regressor** as the best-performing model.
- Generated final predictions on the test set.

### 8Ô∏è‚É£ Submission
- Converted predictions back to the original scale using `np.exp()`.
- Created a submission file (CSV) containing the predicted `SalePrice`.

## üî• Feature Importance Analysis (Post-Prediction Recommendation)
Feature importance analysis helps determine which **input variables (features) have the most impact** on the target variable in a predictive model. This analysis enhances model interpretability and can guide future feature selection. The histogram below shows the **top 30 important features** based on their impact.

## üìä Best Model Selection
### From the Comparison Table, **Voting Regressor** outperformed all models in accuracy and stability, as it has:
- **Lowest RMSE** (TBD) ‚Üí Indicates minimal prediction error.
- **Highest R¬≤ Score** (TBD) ‚Üí Shows strong predictive power.
- **Lowest MAPE** (TBD%) ‚Üí Suggests better relative accuracy compared to others.

## üìÇ Technologies Used
- **Python** (`pandas`, `numpy`, `matplotlib`, `seaborn`)
- **Scikit-learn** (`LinearRegression`, `RandomForestRegressor`, `GradientBoostingRegressor`, `GridSearchCV`)
- **XGBoost**, **CatBoost**, **LGBM**
- **Feature Engineering & Data Preprocessing** (`ColumnTransformer`, `OneHotEncoding`, `StandardScaler`)

## üìå Conclusion
This project demonstrated the effectiveness of machine learning in predicting house prices. By leveraging multiple regression models and feature engineering, a highly accurate predictive model was developed. The insights gained can help real estate professionals and buyers make **data-driven** decisions based on model predictions.

 

## **üìÇ Technologies Used**  
- **Python** (`pandas`, `numpy`, `matplotlib`, `seaborn`)  
- **Scikit-learn** (`LinearRegression`, `RandomForestRegressor`, `GradientBoostingRegressor`, `GridSearchCV`)  
- **XGBoost, CatBoost, LGBM**  
- **Feature Engineering & Data Preprocessing** (`ColumnTransformer`, `OneHotEncoding`, `StandardScaler`)  
